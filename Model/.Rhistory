C.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/Cholesterol.csv", header=TRUE, as.is=TRUE)
View(C.df)
C.df$Cereal <- as.factor(C.df$Cereal)
```
```{r setup, include=FALSE}
library(knitr)
library(dplyr)
library(ggplot2)
library(BSDA)
source("Functions.R")
knitr::opts_chunk$set(echo = TRUE)
SHOW_SOLUTIONS = TRUE
```
Read in the ice cream, birthweight, and cholesterol data sets.
```{r, eval=TRUE}
IC.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/IceCream.csv", header=TRUE, as.is=TRUE)
IC.df$Sex <- as.factor(IC.df$Sex)
IC.df$Flavor <- as.factor(IC.df$Flavor)
#
BW.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/BirthWeight.csv", header=TRUE, as.is=TRUE)
BW.df$Smoker <- as.factor(BW.df$Smoker)
BW.df$BirthWt <- as.factor(BW.df$BirthWt)
BW.df$MAgeGT35 <- as.factor(BW.df$MAgeGT35)
#
C.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/Cholesterol.csv", header=TRUE, as.is=TRUE)
View(C.df)
C.df$Cereal <- as.factor(C.df$Cereal)
```
```{r setup, include=FALSE}
library(knitr)
library(dplyr)
library(ggplot2)
library(BSDA)
source("Functions.R")
knitr::opts_chunk$set(echo = TRUE)
SHOW_SOLUTIONS = TRUE
```
Read the ice cream, birthweight, and cholesterol data sets.
```{r, eval=TRUE}
IC.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/IceCream.csv", header=TRUE, as.is=TRUE)
IC.df$Sex <- as.factor(IC.df$Sex)
IC.df$Flavor <- as.factor(IC.df$Flavor)
#
BW.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/BirthWeight.csv", header=TRUE, as.is=TRUE)
BW.df$Smoker <- as.factor(BW.df$Smoker)
BW.df$BirthWt <- as.factor(BW.df$BirthWt)
BW.df$MAgeGT35 <- as.factor(BW.df$MAgeGT35)
#
C.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/Cholesterol.csv", header=TRUE, as.is=TRUE)
View(C.df)
C.df$Cereal <- as.factor(C.df$Cereal)
```
```{r setup, include=FALSE}
library(knitr)
library(dplyr)
library(ggplot2)
library(BSDA)
source("Functions.R")
knitr::opts_chunk$set(echo = TRUE)
SHOW_SOLUTIONS = TRUE
```
Read the ice cream, birthweight, and cholesterol data sets.
```{r, eval=TRUE}
IC.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/IceCream.csv", header=TRUE, as.is=TRUE)
IC.df$Sex <- as.factor(IC.df$Sex)
IC.df$Flavor <- as.factor(IC.df$Flavor)
#
BW.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/BirthWeight.csv", header=TRUE, as.is=TRUE)
BW.df$Smoker <- as.factor(BW.df$Smoker)
BW.df$BirthWt <- as.factor(BW.df$BirthWt)
BW.df$MAgeGT35 <- as.factor(BW.df$MAgeGT35)
#
C.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/Cholesterol.csv", header=TRUE, as.is=TRUE)
View(C.df)
C.df$Cereal <- as.factor(C.df$Cereal)
```
library(knitr)
library(dplyr)
library(ggplot2)
library(BSDA)
source("Functions.R")
knitr::opts_chunk$set(echo = TRUE)
SHOW_SOLUTIONS = TRUE
IC.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/IceCream.csv", header=TRUE, as.is=TRUE)
IC.df$Sex <- as.factor(IC.df$Sex)
IC.df$Flavor <- as.factor(IC.df$Flavor)
#
BW.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/BirthWeight.csv", header=TRUE, as.is=TRUE)
BW.df$Smoker <- as.factor(BW.df$Smoker)
BW.df$BirthWt <- as.factor(BW.df$BirthWt)
BW.df$MAgeGT35 <- as.factor(BW.df$MAgeGT35)
#
C.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/Cholesterol.csv", header=TRUE, as.is=TRUE)
View(C.df)
C.df$Cereal <- as.factor(C.df$Cereal)
IC.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/IceCream.csv", header=TRUE, as.is=TRUE)
IC.df$Sex <- as.factor(IC.df$Sex)
IC.df$Flavor <- as.factor(IC.df$Flavor)
#
BW.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/BirthWeight.csv", header=TRUE, as.is=TRUE)
BW.df$Smoker <- as.factor(BW.df$Smoker)
BW.df$BirthWt <- as.factor(BW.df$BirthWt)
BW.df$MAgeGT35 <- as.factor(BW.df$MAgeGT35)
#
C.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/Cholesterol.csv", header=TRUE, as.is=TRUE)
View(C.df)
C.df$Cereal <- as.factor(C.df$Cereal)
IC.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/IceCream.csv", header=TRUE, as.is=TRUE)
IC.df$Sex <- as.factor(IC.df$Sex)
IC.df$Flavor <- as.factor(IC.df$Flavor)
view(IC.df)
IC.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/IceCream.csv", header=TRUE, as.is=TRUE)
IC.df$Sex <- as.factor(IC.df$Sex)
IC.df$Flavor <- as.factor(IC.df$Flavor)
View(IC.df)
#
BW.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/BirthWeight.csv", header=TRUE, as.is=TRUE)
BW.df$Smoker <- as.factor(BW.df$Smoker)
BW.df$BirthWt <- as.factor(BW.df$BirthWt)
BW.df$MAgeGT35 <- as.factor(BW.df$MAgeGT35)
View(BW.df)
#
C.df <- read.csv("E:/DATA SCIENCE JOBS/R-Analysis Significance Test/Background/Cholesterol.csv", header=TRUE, as.is=TRUE)
View(C.df)
C.df$Cereal <- as.factor(C.df$Cereal)
# Look at the t.test help file
?t.test
# First interval is 95%, which is the default if you do
# not specify conf.level
t.test(IC.df$Weight)$conf.int
View(IC.df)
# Look at the t.test help file
?t.test
# First interval is 95%, which is the default if you do
# not specify conf.level
t.test(IC.df$Puzzle)$conf.int
t.test(IC.df$Puzzle, conf.level=0.95)$conf.int
# First get the right subset of data
D.CD <- filter(IC.df, Flavor == "D")
D.CI <- filter(IC.df, Flavor == "I")
# Look at the samples sizes and samples SDs for each group
# to inform the decision for un-pooled or pooled variance.
n.CD <- nrow(D.CD)
sd.CD <- sd(D.CD$Weight)
n.CI <- nrow(D.CI)
sd.CI <- sd(D.CI$Weight)
cbind(nCD = n.CD, SD.CD = sd.CD, nCI = n.CI, SD.CI = sd.CI)
# The sample size for color D is smallish; the two sample
# SDs are similar. This could go either way. If we pool,
# we will be giving a higher weight to the lower variance.
# Checking our ROT gives us a ratio < 3 (code shown below),
# so pooling is probably okay.
sd.CD^2/sd.CI^2
# Using un-pooled would be most conservative. At the same time
# pooling may be reasonable because we might expect the
# population variances to be similar for Weight (would we expect
# the variation in Weight to be different for different colors?).
# We will run it both ways here so you can see the difference--in
# practice, you would make a choice based on your understanding
# of diamond weights and go from there.
# First interval is 95% using an un-pooled variance, both are
# defaults
t.test(D.CD$Weight, D.CI$Weight)$conf.int
# First get the right subset of data
D.CD <- filter(IC.df, Flavor == "D")
D.CI <- filter(IC.df, Flavor == "I")
# Look at the samples sizes and samples SDs for each group
# to inform the decision for un-pooled or pooled variance.
n.CD <- nrow(D.CD)
sd.CD <- sd(D.CD$Puzzle)
n.CI <- nrow(D.CI)
sd.CI <- sd(D.CI$Puzzle)
cbind(nCD = n.CD, SD.CD = sd.CD, nCI = n.CI, SD.CI = sd.CI)
# The sample size for color D is smallish; the two sample
# SDs are similar. This could go either way. If we pool,
# we will be giving a higher weight to the lower variance.
# Checking our ROT gives us a ratio < 3 (code shown below),
# so pooling is probably okay.
sd.CD^2/sd.CI^2
# Using un-pooled would be most conservative. At the same time
# pooling may be reasonable because we might expect the
# population variances to be similar for Weight (would we expect
# the variation in Weight to be different for different colors?).
# We will run it both ways here so you can see the difference--in
# practice, you would make a choice based on your understanding
# of diamond weights and go from there.
# First interval is 95% using an un-pooled variance, both are
# defaults
t.test(D.CD$Puzzle, D.CI$Puzzle)$conf.int
# First get the right subset of data
D.CD <- filter(IC.df, Flavor == "D")
D.CI <- filter(IC.df, Flavor == "I")
# Look at the samples sizes and samples SDs for each group
# to inform the decision for un-pooled or pooled variance.
n.CD <- nrow(D.CD)
sd.CD <- sd(D.CD$Puzzle)
n.CI <- nrow(D.CI)
sd.CI <- sd(D.CI$Puzzle)
cbind(nCD = n.CD, SD.CD = sd.CD, nCI = n.CI, SD.CI = sd.CI)
# The sample size for color D is smallish; the two sample
# SDs are similar. This could go either way. If we pool,
# we will be giving a higher weight to the lower variance.
# Checking our ROT gives us a ratio < 3 (code shown below),
# so pooling is probably okay.
sd.CD^2/sd.CI^2
# Using un-pooled would be most conservative. At the same time
# pooling may be reasonable because we might expect the
# population variances to be similar for Weight (would we expect
# the variation in Weight to be different for different colors?).
# We will run it both ways here so you can see the difference--in
# practice, you would make a choice based on your understanding
# of diamond weights and go from there.
# First interval is 95% using an un-pooled variance, both are
# defaults
t.test(D.CD$Puzzle, D.CI$Puzzle)$conf.int
# First get the right subset of data
D.CD <- filter(IC.df, Flavor == "1")
D.CI <- filter(IC.df, Flavor == "2")
# Look at the samples sizes and samples SDs for each group
# to inform the decision for un-pooled or pooled variance.
n.CD <- nrow(D.CD)
sd.CD <- sd(D.CD$Puzzle)
n.CI <- nrow(D.CI)
sd.CI <- sd(D.CI$Puzzle)
cbind(nCD = n.CD, SD.CD = sd.CD, nCI = n.CI, SD.CI = sd.CI)
# The sample size for color D is smallish; the two sample
# SDs are similar. This could go either way. If we pool,
# we will be giving a higher weight to the lower variance.
# Checking our ROT gives us a ratio < 3 (code shown below),
# so pooling is probably okay.
sd.CD^2/sd.CI^2
# Using un-pooled would be most conservative. At the same time
# pooling may be reasonable because we might expect the
# population variances to be similar for Weight (would we expect
# the variation in Weight to be different for different colors?).
# We will run it both ways here so you can see the difference--in
# practice, you would make a choice based on your understanding
# of diamond weights and go from there.
# First interval is 95% using an un-pooled variance, both are
# defaults
t.test(D.CD$Puzzle, D.CI$Puzzle)$conf.int
# Same interval as above but with pooled variance
t.test(D.CD$Puzzle, D.CI$Puzzle, var.equal=TRUE)$conf.int
# First get the right subset of data
D.CD <- filter(IC.df, Flavor == "1")
D.CI <- filter(IC.df, Flavor == "2")
# Look at the samples sizes and samples SDs for each group
# to inform the decision for un-pooled or pooled variance.
n.CD <- nrow(D.CD)
sd.CD <- sd(D.CD$Puzzle)
n.CI <- nrow(D.CI)
sd.CI <- sd(D.CI$Puzzle)
cbind(nCD = n.CD, SD.CD = sd.CD, nCI = n.CI, SD.CI = sd.CI)
# The sample size for color D is smallish; the two sample
# SDs are similar. This could go either way. If we pool,
# we will be giving a higher weight to the lower variance.
# Checking our ROT gives us a ratio < 3 (code shown below),
# so pooling is probably okay.
sd.CD^2/sd.CI^2
# Using un-pooled would be most conservative. At the same time
# pooling may be reasonable because we might expect the
# population variances to be similar for Weight (would we expect
# the variation in Weight to be different for different colors?).
# We will run it both ways here so you can see the difference--in
# practice, you would make a choice based on your understanding
# of diamond weights and go from there.
# First interval is 95% using an un-pooled variance, both are
# defaults
t.test(D.CD$Puzzle, D.CI$Puzzle)$conf.int
# Same interval as above but with pooled variance
t.test(D.CD$Puzzle, D.CI$Puzzle, var.equal=TRUE)$conf.int
# Same two calls from above after removing the $conf.int at
# the end to see all the t.test output
t.test(D.CD$Puzzle, D.CI$Puzzle)
t.test(D.CD$Puzzle, D.CI$Puzzle, var.equal=TRUE)
# First get the right subset of data
D.CD <- filter(IC.df, Flavor == "1")
D.CI <- filter(IC.df, Flavor == "2")
# Look at the samples sizes and samples SDs for each group
# to inform the decision for un-pooled or pooled variance.
n.CD <- nrow(D.CD)
sd.CD <- sd(D.CD$Puzzle)
n.CI <- nrow(D.CI)
sd.CI <- sd(D.CI$Puzzle)
cbind(nCD = n.CD, SD.CD = sd.CD, nCI = n.CI, SD.CI = sd.CI)
# The sample size for color D is smallish; the two sample
# SDs are similar. This could go either way. If we pool,
# we will be giving a higher weight to the lower variance.
# Checking our ROT gives us a ratio < 3 (code shown below),
# so pooling is probably okay.
sd.CD^2/sd.CI^2
# Using un-pooled would be most conservative. At the same time
# pooling may be reasonable because we might expect the
# population variances to be similar for Weight (would we expect
# the variation in Weight to be different for different colors?).
# We will run it both ways here so you can see the difference--in
# practice, you would make a choice based on your understanding
# of diamond weights and go from there.
# First interval is 95% using an un-pooled variance, both are
# defaults
t.test(D.CD$Puzzle, D.CI$Puzzle,conf.level=0.01)$conf.int
# Same interval as above but with pooled variance
t.test(D.CD$Puzzle, D.CI$Puzzle, var.equal=TRUE)$conf.int
# First get the right subset of data
D.CD <- filter(IC.df, Flavor == "1")
D.CI <- filter(IC.df, Flavor == "2")
# Look at the samples sizes and samples SDs for each group
# to inform the decision for un-pooled or pooled variance.
n.CD <- nrow(D.CD)
sd.CD <- sd(D.CD$Puzzle)
n.CI <- nrow(D.CI)
sd.CI <- sd(D.CI$Puzzle)
cbind(nCD = n.CD, SD.CD = sd.CD, nCI = n.CI, SD.CI = sd.CI)
# The sample size for color D is smallish; the two sample
# SDs are similar. This could go either way. If we pool,
# we will be giving a higher weight to the lower variance.
# Checking our ROT gives us a ratio < 3 (code shown below),
# so pooling is probably okay.
sd.CD^2/sd.CI^2
# Using un-pooled would be most conservative. At the same time
# pooling may be reasonable because we might expect the
# population variances to be similar for Weight (would we expect
# the variation in Weight to be different for different colors?).
# We will run it both ways here so you can see the difference--in
# practice, you would make a choice based on your understanding
# of diamond weights and go from there.
# First interval is 95% using an un-pooled variance, both are
# defaults
t.test(D.CD$Puzzle, D.CI$Puzzle,conf.level=0.01)$conf.int
# Same interval as above but with pooled variance
t.test(D.CD$Puzzle, D.CI$Puzzle, var.equal=TRUE)$conf.int
# Same two calls from above after removing the $conf.int at
# the end to see all the t.test output
t.test(D.CD$Puzzle, D.CI$Puzzle,conf.level=0.01)$conf.int
t.test(D.CD$Puzzle, D.CI$Puzzle, var.equal=TRUE)
# Test the claim that students with a preference for strawberry ice cream have higher puzzle scores than students that prefer chocolate ice cream. Use strawberry minus chocolate and a 1% significance level. Assume the population variances are not equal.
# Enter measured, then reported as stated in the problem statement
# Add the paired=TRUE argument to let R know that the data are
# matched pairs. Set the conf.level to 0.01
t.test(IC.df$Flavor=="1",IC.df$Flavor=="3", paired=TRUE,
conf.level = 0.01)$conf.int
# The three arguments passed to the function are
# x = number of successes, n = total number of observations
# and conf.level. We will default conf.level to 0.95.
oneprop.CI <- function(x, n, conf.level=0.95) {
phat <- x/n
qhat <- 1 - phat
se.phat <- sqrt(phat*qhat/n)
alphaO2 <- (1 - conf.level)/2
zcrit <- abs(qnorm(alphaO2))
LB <- phat - (zcrit*(se.phat))
UB <- phat + (zcrit*(se.phat))
result <- cbind(phat = phat, Lower = LB, Upper = UB)
return(result)
}
tab1 <- table(BW.df$Smoker)
sum(tab1)*(tab1[1]/sum(tab1)) #nphat
sum(tab1)*(1-(tab1[1]/sum(tab1))) #n(1-phat) = nqhat
oneprop.CI(tab1[1], sum(tab1), conf.level=0.98)
# The five arguments passed to the function are
# x1 = number of successes in sample 1, n1 = total number of observations
# in sample 1, x2 = number of successes in sample 2,
# n2 = total number of observations in sample 2, and
# and conf.level. We will default conf.level to 0.95.
twoprop.CI <- function(x1, n1, x2, n2, conf.level=0.95) {
phat1 <- x1/n1
qhat1 <- 1 - phat1
phat2<- x2/n2
qhat2 <- 1 - phat2
diff.phat <- phat1 - phat2
se.phat <- sqrt((phat1*qhat1/n1) + (phat2*qhat2/n2))
alphaO2 <- (1 - conf.level)/2
zcrit <- abs(qnorm(alphaO2))
LB <- diff.phat - (zcrit*(se.phat))
UB <- diff.phat + (zcrit*(se.phat))
result <- cbind(diff = diff.phat, Lower = LB, Upper = UB)
return(result)
}
# The five arguments passed to the function are
# x1 = number of successes in sample 1, n1 = total number of observations
# in sample 1, x2 = number of successes in sample 2,
# n2 = total number of observations in sample 2, and
# and conf.level. We will default conf.level to 0.95.
twoprop.CI <- function(x1, n1, x2, n2, conf.level=0.95) {
phat1 <- x1/n1
qhat1 <- 1 - phat1
phat2<- x2/n2
qhat2 <- 1 - phat2
diff.phat <- phat1 - phat2
se.phat <- sqrt((phat1*qhat1/n1) + (phat2*qhat2/n2))
alphaO2 <- (1 - conf.level)/2
zcrit <- abs(qnorm(alphaO2))
LB <- diff.phat - (zcrit*(se.phat))
UB <- diff.phat + (zcrit*(se.phat))
result <- cbind(diff = diff.phat, Lower = LB, Upper = UB)
return(result)
}
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2[4,]) * tab2[4,5]/sum(tab2[4,]) # n1phat1
# The five arguments passed to the function are
# x1 = number of successes in sample 1, n1 = total number of observations
# in sample 1, x2 = number of successes in sample 2,
# n2 = total number of observations in sample 2, and
# and conf.level. We will default conf.level to 0.95.
twoprop.CI <- function(x1, n1, x2, n2, conf.level=0.95) {
phat1 <- x1/n1
qhat1 <- 1 - phat1
phat2<- x2/n2
qhat2 <- 1 - phat2
diff.phat <- phat1 - phat2
se.phat <- sqrt((phat1*qhat1/n1) + (phat2*qhat2/n2))
alphaO2 <- (1 - conf.level)/2
zcrit <- abs(qnorm(alphaO2))
LB <- diff.phat - (zcrit*(se.phat))
UB <- diff.phat + (zcrit*(se.phat))
result <- cbind(diff = diff.phat, Lower = LB, Upper = UB)
return(result)
}
# The five arguments passed to the function are
# x1 = number of successes in sample 1, n1 = total number of observations
# in sample 1, x2 = number of successes in sample 2,
# n2 = total number of observations in sample 2, and
# and conf.level. We will default conf.level to 0.95.
twoprop.CI <- function(x1, n1, x2, n2, conf.level=0.95) {
phat1 <- x1/n1
qhat1 <- 1 - phat1
phat2<- x2/n2
qhat2 <- 1 - phat2
diff.phat <- phat1 - phat2
se.phat <- sqrt((phat1*qhat1/n1) + (phat2*qhat2/n2))
alphaO2 <- (1 - conf.level)/2
zcrit <- abs(qnorm(alphaO2))
LB <- diff.phat - (zcrit*(se.phat))
UB <- diff.phat + (zcrit*(se.phat))
result <- cbind(diff = diff.phat, Lower = LB, Upper = UB)
return(result)
}
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2[4,]) * tab2[4,5]/sum(tab2[4,]) # n1phat1
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2,4) * tab2[4,5]/sum(tab2[4,]) # n1phat1
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2,4,) * tab2[4,5]/sum(tab2[4,]) # n1phat1
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2,4) * tab2[4,5]/sum(tab2[4,]) # n1phat1
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2,[4]) * tab2[4,5]/sum(tab2[4,]) # n1phat1
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2[4]) * tab2[4,5]/sum(tab2[4,]) # n1phat1
twoprop.CI(tab2[4,5], sum(tab2[4,]), tab2[5,5], sum(tab2[5,]), conf.level=0.98)
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2[4]) * tab2[4,5]/sum(tab2[4,]) # n1phat1
twoprop.CI(tab2[4,5], sum(tab2[4,]), tab2[5,5], sum(tab2[5,]), conf.level=0.05)
# The five arguments passed to the function are
# x1 = number of successes in sample 1, n1 = total number of observations
# in sample 1, x2 = number of successes in sample 2,
# n2 = total number of observations in sample 2, and
# and conf.level. We will default conf.level to 0.95.
twoprop.CI <- function(x1, n1, x2, n2, conf.level=0.05) {
phat1 <- x1/n1
qhat1 <- 1 - phat1
phat2<- x2/n2
qhat2 <- 1 - phat2
diff.phat <- phat1 - phat2
se.phat <- sqrt((phat1*qhat1/n1) + (phat2*qhat2/n2))
alphaO2 <- (1 - conf.level)/2
zcrit <- abs(qnorm(alphaO2))
LB <- diff.phat - (zcrit*(se.phat))
UB <- diff.phat + (zcrit*(se.phat))
result <- cbind(diff = diff.phat, Lower = LB, Upper = UB)
return(result)
}
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2[4]) * tab2[4,5]/sum(tab2[4,]) # n1phat1
tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1")
sum(tab2[4]) * tab2[4,5]/sum(tab2[4,]) # n1phat1
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2[4]) * tab2[4,5]/sum(tab2[4,])   # n1phat1
twoprop.CI(tab2[4,5], sum(tab2[4,]), tab2[5,5], sum(tab2[5,]), conf.level=0.05)
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2[3]) * tab2[4,5]/sum(tab2[4,])   # n1phat1
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2[3]) * tab2[4,2]/sum(tab2[4,])   # n1phat1
twoprop.CI(tab2[4,5], sum(tab2[4,]), tab2[5,5], sum(tab2[5,]), conf.level=0.05)
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
sum(tab2[4]) * tab2[4,5]/sum(tab2[4,])   # n1phat1
# The three arguments passed to the function are
# x = number of successes, n = total number of observations
# and conf.level. We will default conf.level to 0.05.
oneprop.HT <- function(x, n, pmu=0, alternative="two.sided",conf.level=0.05) {
phat <- x/n
se.phat <- sqrt(pmu*(1-pmu)/n)
z.score <- (phat - pmu)/se.phat
p.value <- 1 - pnorm(abs(z.score)) #upper tail
if (alternative == "two.sided") p.value = 2*p.value
result <- cbind(phat = phat, zStat = z.score, pValue = p.value)
return(result)
}
oneprop.HT(tab1[1], sum(tab1), pmu = 0.10)
View(Cholesterol)
View(Cholesterol)
(tab1 <- table(C.df$Cereal=="OatBran", BW.df$Cereal=="Cornflk"))
(tab1 <- table(C.df$Cereal=="OatBran", C.df$Cereal=="Cornflk"))
oneprop.HT(tab1[1], sum(tab1), pmu = 0.10)
library(knitr)
library(dplyr)
library(ggplot2)
library(BSDA)
source("Functions.R")
knitr::opts_chunk$set(echo = TRUE)
SHOW_SOLUTIONS = TRUE
(tab2 <- table(BW.df$Smoker=="0", BW.df$Smoker=="1"))
